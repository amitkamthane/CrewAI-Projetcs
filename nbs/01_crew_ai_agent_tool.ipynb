{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae53a09-c04c-4916-a146-00e0bb188954",
   "metadata": {},
   "source": [
    "#### Automated Project: Planning, Estimation, and Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4193708e-9802-4161-844a-735f6361e24d",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "from helper import load_env\n",
    "load_env()\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b930b575-a2d5-467b-878f-de78e10b6ba5",
   "metadata": {},
   "source": [
    "#### Set OpenAI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91cb8100-3058-4cdc-969b-c64a46a408e4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_MODEL_NAME'] = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b83836-9ccb-47d7-a97b-9a68aebfaa42",
   "metadata": {},
   "source": [
    "#### Loading Tasks and Agents YAML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a4e362d-c010-43dd-88c4-e7db87834fb4",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "# Define file paths for YAML configurations\n",
    "files = {\n",
    "    'agents': '../../configs/agents.yaml',\n",
    "    'tasks': '../../configs/tasks.yaml'\n",
    "}\n",
    "\n",
    "# Load configurations from YAML files\n",
    "configs = {}\n",
    "for config_type, file_path in files.items():\n",
    "    with open(file_path, 'r') as file:\n",
    "        configs[config_type] = yaml.safe_load(file)\n",
    "\n",
    "# Assign loaded configurations to specific variables\n",
    "agents_config = configs['agents']\n",
    "tasks_config = configs['tasks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f50c89-a326-4e4c-93a1-79be3fcda14b",
   "metadata": {},
   "source": [
    "#### Create Pydantic Models for Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e8626d2-e48a-4b7e-a061-a8eb492c9036",
   "metadata": {
    "height": 283
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TaskEstimate(BaseModel):\n",
    "    task_name: str = Field(..., description=\"Name of the task\")\n",
    "    estimated_time_hours: float = Field(..., description=\"Estimated time to complete the task in hours\")\n",
    "    required_resources: List[str] = Field(..., description=\"List of resources required to complete the task\")\n",
    "\n",
    "class Milestone(BaseModel):\n",
    "    milestone_name: str = Field(..., description=\"Name of the milestone\")\n",
    "    tasks: List[str] = Field(..., description=\"List of task IDs associated with this milestone\")\n",
    "\n",
    "class ProjectPlan(BaseModel):\n",
    "    tasks: List[TaskEstimate] = Field(..., description=\"List of tasks with their estimates\")\n",
    "    milestones: List[Milestone] = Field(..., description=\"List of project milestones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d6524c-48e7-460e-8345-3b7a872b714a",
   "metadata": {},
   "source": [
    "## Create Crew, Agents and Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a655927f-c10c-4c06-852a-d9c96fdfbfb9",
   "metadata": {
    "height": 761
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\openai-4o\\lib\\site-packages\\pydantic\\_internal\\_config.py:291: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Creating Agents\n",
    "project_planning_agent = Agent(\n",
    "  config=agents_config['project_planning_agent']\n",
    ")\n",
    "\n",
    "estimation_agent = Agent(\n",
    "  config=agents_config['estimation_agent']\n",
    ")\n",
    "\n",
    "resource_allocation_agent = Agent(\n",
    "  config=agents_config['resource_allocation_agent']\n",
    ")\n",
    "\n",
    "# Creating Tasks\n",
    "task_breakdown = Task(\n",
    "  config=tasks_config['task_breakdown'],\n",
    "  agent=project_planning_agent\n",
    ")\n",
    "\n",
    "time_resource_estimation = Task(\n",
    "  config=tasks_config['time_resource_estimation'],\n",
    "  agent=estimation_agent\n",
    ")\n",
    "\n",
    "resource_allocation = Task(\n",
    "  config=tasks_config['resource_allocation'],\n",
    "  agent=resource_allocation_agent,\n",
    "  output_pydantic=ProjectPlan # This is the structured output we want\n",
    ")\n",
    "\n",
    "# Creating Crew\n",
    "crew = Crew(\n",
    "  agents=[\n",
    "    project_planning_agent,\n",
    "    estimation_agent,\n",
    "    resource_allocation_agent\n",
    "  ],\n",
    "  tasks=[\n",
    "    task_breakdown,\n",
    "    time_resource_estimation,\n",
    "    resource_allocation\n",
    "  ],\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b901cf-3630-4662-81a7-762da6773d3b",
   "metadata": {},
   "source": [
    "## Crew's Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e861574-0f9b-4f2c-b2d1-a230fc3a53a3",
   "metadata": {
    "height": 708
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Project Type:** RAG (Retrieval-Augmented Generation) LLM\n",
       "\n",
       "**Project Objectives:** Build a RAG-based system to generate contextually accurate and detailed responses by augmenting a language model with external information retrieved in real-time.\n",
       "\n",
       "**Industry:** AI/Technology\n",
       "\n",
       "**Team Members:**\n",
       "\n",
       "- Jack White (Project Manager)\n",
       "- Olivia Stone (AI Researcher)\n",
       "- Ethan Clark (ML Engineer)\n",
       "- Maria Green (Data Engineer)\n",
       "- Sofia Patel (NLP Engineer)\n",
       "- Liam Allen (QA Engineer)\n",
       "\n",
       "\n",
       "**Project Requirements:**\n",
       "\n",
       "- Integrate a large pre-trained language model (e.g., GPT-4, T5) with a retrieval mechanism (e.g., Elasticsearch, FAISS, Pinecone)\n",
       "- Implement an efficient data retrieval system to fetch contextually relevant documents or knowledge\n",
       "- Use the retrieved data to augment the model's generation process for more accurate and relevant responses\n",
       "- Implement document ranking and relevance scoring for retrieved data\n",
       "- Ensure the system can process large volumes of unstructured text from diverse sources (web, APIs, databases)\n",
       "- Fine-tune the LLM on specific use-cases, e.g., customer support, technical assistance, etc.\n",
       "- Evaluate and optimize the retrieval strategy to minimize latency while ensuring accurate and diverse responses\n",
       "- Test the LLM’s response quality, ensuring the output is context-aware and doesn't rely solely on training data\n",
       "- Implement an interface to manage the retrieval and generation pipeline for easy user interaction\n",
       "- Ensure scalability to handle multiple simultaneous user requests and queries\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "project = 'RAG (Retrieval-Augmented Generation) LLM'\n",
    "industry = 'AI/Technology'\n",
    "project_objectives = 'Build a RAG-based system to generate contextually accurate and detailed responses by augmenting a language model with external information retrieved in real-time.'\n",
    "team_members = \"\"\"\n",
    "- Jack White (Project Manager)\n",
    "- Olivia Stone (AI Researcher)\n",
    "- Ethan Clark (ML Engineer)\n",
    "- Maria Green (Data Engineer)\n",
    "- Sofia Patel (NLP Engineer)\n",
    "- Liam Allen (QA Engineer)\n",
    "\"\"\"\n",
    "project_requirements = \"\"\"\n",
    "- Integrate a large pre-trained language model (e.g., GPT-4, T5) with a retrieval mechanism (e.g., Elasticsearch, FAISS, Pinecone)\n",
    "- Implement an efficient data retrieval system to fetch contextually relevant documents or knowledge\n",
    "- Use the retrieved data to augment the model's generation process for more accurate and relevant responses\n",
    "- Implement document ranking and relevance scoring for retrieved data\n",
    "- Ensure the system can process large volumes of unstructured text from diverse sources (web, APIs, databases)\n",
    "- Fine-tune the LLM on specific use-cases, e.g., customer support, technical assistance, etc.\n",
    "- Evaluate and optimize the retrieval strategy to minimize latency while ensuring accurate and diverse responses\n",
    "- Test the LLM’s response quality, ensuring the output is context-aware and doesn't rely solely on training data\n",
    "- Implement an interface to manage the retrieval and generation pipeline for easy user interaction\n",
    "- Ensure scalability to handle multiple simultaneous user requests and queries\n",
    "\"\"\"\n",
    "\n",
    "# Format the dictionary as Markdown for a better display in Jupyter Lab\n",
    "formatted_output = f\"\"\"\n",
    "**Project Type:** {project}\n",
    "\n",
    "**Project Objectives:** {project_objectives}\n",
    "\n",
    "**Industry:** {industry}\n",
    "\n",
    "**Team Members:**\n",
    "{team_members}\n",
    "\n",
    "**Project Requirements:**\n",
    "{project_requirements}\n",
    "\"\"\"\n",
    "\n",
    "# Display the formatted output as Markdown\n",
    "display(Markdown(formatted_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15198e13-e9ec-44d8-b15e-c97b7b7320bb",
   "metadata": {},
   "source": [
    "## Kicking off the crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa40b53e-0a49-4198-a263-c79a6a3af603",
   "metadata": {
    "height": 234
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mThe Ultimate Project Planner\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mLook at the RAG (Retrieval-Augmented Generation) LLM project requirements and break them down into smaller tasks. Define what each task involves, set achievable timelines, and make sure to consider all dependencies:\n",
      "\n",
      "- Integrate a large pre-trained language model (e.g., GPT-4, T5) with a retrieval mechanism (e.g., Elasticsearch, FAISS, Pinecone)\n",
      "- Implement an efficient data retrieval system to fetch contextually relevant documents or knowledge\n",
      "- Use the retrieved data to augment the model's generation process for more accurate and relevant responses\n",
      "- Implement document ranking and relevance scoring for retrieved data\n",
      "- Ensure the system can process large volumes of unstructured text from diverse sources (web, APIs, databases)\n",
      "- Fine-tune the LLM on specific use-cases, e.g., customer support, technical assistance, etc.\n",
      "- Evaluate and optimize the retrieval strategy to minimize latency while ensuring accurate and diverse responses\n",
      "- Test the LLM’s response quality, ensuring the output is context-aware and doesn't rely solely on training data\n",
      "- Implement an interface to manage the retrieval and generation pipeline for easy user interaction\n",
      "- Ensure scalability to handle multiple simultaneous user requests and queries\n",
      "\n",
      "Team members:\n",
      "\n",
      "- Jack White (Project Manager)\n",
      "- Olivia Stone (AI Researcher)\n",
      "- Ethan Clark (ML Engineer)\n",
      "- Maria Green (Data Engineer)\n",
      "- Sofia Patel (NLP Engineer)\n",
      "- Liam Allen (QA Engineer)\n",
      "\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mThe Ultimate Project Planner\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "**RAG (Retrieval-Augmented Generation) LLM Project Breakdown**\n",
      "\n",
      "### Breakdown of Tasks\n",
      "\n",
      "1. **Integrate a Large Pre-trained Language Model**\n",
      "   - **Description**: Select and integrate a suitable large pre-trained language model (e.g., GPT-4, T5) with the retrieval framework.\n",
      "   - **Responsible**: Ethan Clark (ML Engineer)\n",
      "   - **Timeline**: Week 1-2\n",
      "   - **Dependencies**: Completion of model selection and validation phase.\n",
      "   - **Deliverable**: Integrated language model set up with access mechanisms.\n",
      "\n",
      "2. **Implement an Efficient Data Retrieval System**  \n",
      "   - **Description**: Set up and configure a data retrieval system (e.g., Elasticsearch, FAISS, Pinecone) to fetch contextually relevant documents.\n",
      "   - **Responsible**: Maria Green (Data Engineer)\n",
      "   - **Timeline**: Week 3-4\n",
      "   - **Dependencies**: Completion of model integration phase.\n",
      "   - **Deliverable**: Functioning data retrieval system capable of executing queries.\n",
      "\n",
      "3. **Augment Model Generation Process**\n",
      "   - **Description**: Develop the logic to incorporate retrieved data into the language model's output generation.\n",
      "   - **Responsible**: Olivia Stone (AI Researcher) & Ethan Clark (ML Engineer)\n",
      "   - **Timeline**: Week 5-6\n",
      "   - **Dependencies**: Completion of data retrieval system.\n",
      "   - **Deliverable**: Enhanced response generation mechanism employing retrieved data.\n",
      "\n",
      "4. **Implement Document Ranking and Relevance Scoring**\n",
      "   - **Description**: Design and implement algorithms for document ranking and scoring based on relevance.\n",
      "   - **Responsible**: Sofia Patel (NLP Engineer)\n",
      "   - **Timeline**: Week 5-6 (parallel with augmentation)\n",
      "   - **Dependencies**: Completion of data retrieval system.\n",
      "   - **Deliverable**: Document ranking system integrated into retrieval process.\n",
      "\n",
      "5. **Process Unstructured Text from Diverse Sources**\n",
      "   - **Description**: Develop a pipeline to handle and preprocess large volumes of unstructured text from various sources.\n",
      "   - **Responsible**: Maria Green (Data Engineer)\n",
      "   - **Timeline**: Week 4-7\n",
      "   - **Dependencies**: Establish retrieval mechanisms and data model.\n",
      "   - **Deliverable**: Workflow for unstructured data processing.\n",
      "\n",
      "6. **Fine-tune the LLM on Specific Use-Cases**\n",
      "   - **Description**: Fine-tune the integrated language model based on specified use cases (e.g., customer support).\n",
      "   - **Responsible**: Olivia Stone (AI Researcher) & Ethan Clark (ML Engineer)\n",
      "   - **Timeline**: Week 7-8\n",
      "   - **Dependencies**: Completion of integration and augmentation phases.\n",
      "   - **Deliverable**: LLM fine-tuned on selected use cases.\n",
      "\n",
      "7. **Evaluate and Optimize Retrieval Strategy**\n",
      "   - **Description**: Analyze and optimize the retrieval process for efficiency and accuracy, focusing on latency reduction.\n",
      "   - **Responsible**: Sofia Patel (NLP Engineer) & Ethan Clark (ML Engineer)\n",
      "   - **Timeline**: Week 9\n",
      "   - **Dependencies**: Completion of fine-tuning.\n",
      "   - **Deliverable**: Report on optimization strategies and enhancements implemented.\n",
      "\n",
      "8. **Test the LLM’s Response Quality**\n",
      "   - **Description**: Conduct comprehensive testing on the output quality of the LLM to ensure context-awareness and reliability.\n",
      "   - **Responsible**: Liam Allen (QA Engineer)\n",
      "   - **Timeline**: Week 10\n",
      "   - **Dependencies**: Fine-tuning and optimization completion.\n",
      "   - **Deliverable**: Quality evaluation report with metrics and recommendations.\n",
      "\n",
      "9. **Implement User Interface**\n",
      "   - **Description**: Develop a user-friendly interface to manage the retrieval and generation pipeline.\n",
      "   - **Responsible**: Ethan Clark (ML Engineer) & Maria Green (Data Engineer)\n",
      "   - **Timeline**: Week 11\n",
      "   - **Dependencies**: Completion of response quality testing.\n",
      "   - **Deliverable**: Functional interface for users to interact with the system.\n",
      "\n",
      "10. **Ensure Scalability**\n",
      "    - **Description**: Develop strategies for scaling the system to handle multiple simultaneous user requests.\n",
      "    - **Responsible**: Jack White (Project Manager) & Ethan Clark (ML Engineer)\n",
      "    - **Timeline**: Week 12\n",
      "    - **Dependencies**: Completion of system development and testing.\n",
      "    - **Deliverable**: Scalability plan and implementation confirmation.\n",
      "\n",
      "### Gantt Chart\n",
      "\n",
      "| Task                                     | Week 1 | Week 2 | Week 3 | Week 4 | Week 5 | Week 6 | Week 7 | Week 8 | Week 9 | Week 10 | Week 11 | Week 12 |\n",
      "|------------------------------------------|--------|--------|--------|--------|--------|--------|--------|--------|--------|---------|---------|---------|\n",
      "| Integrate LLM                            |   X    |   X    |        |        |        |        |        |        |        |         |         |         |\n",
      "| Implement Data Retrieval System          |        |        |   X    |   X    |        |        |        |        |        |         |         |         |\n",
      "| Augment Model Generation Process         |        |        |        |        |   X    |   X    |        |        |        |         |         |         |\n",
      "| Implement Document Ranking and Scoring   |        |        |        |        |   X    |   X    |        |        |        |         |         |         |\n",
      "| Process Unstructured Text                |        |        |        |   X    |   X    |   X    |        |        |        |         |         |         |\n",
      "| Fine-tune LLM                           |        |        |        |        |        |        |   X    |   X    |        |         |         |         |\n",
      "| Evaluate and Optimize Retrieval Strategy  |        |        |        |        |        |        |        |        |   X    |         |         |         |\n",
      "| Test LLM’s Response Quality              |        |        |        |        |        |        |        |        |        |    X    |         |         |\n",
      "| Implement User Interface                 |        |        |        |        |        |        |        |        |        |         |    X    |         |\n",
      "| Ensure Scalability                       |        |        |        |        |        |        |        |        |        |         |         |    X    |\n",
      "\n",
      "**Conclusion:**\n",
      "This project breakdown outlines a comprehensive plan to execute the RAG LLM project efficiently, ensuring clear tasks with responsibilities, timelines, dependencies, and deliverables. Cooperation among team members is crucial to accomplish each task efficiently, leading to a successful project outcome that delivers a robust retrieval-augmented language generation system.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mExpert Estimation Analyst\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mGo through each task in the RAG (Retrieval-Augmented Generation) LLM project and estimate how much time, resources, and effort it will take. Use past data, task difficulty, and available resources to make realistic estimates.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mExpert Estimation Analyst\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "### RAG (Retrieval-Augmented Generation) LLM Project Estimation Report\n",
      "\n",
      "#### 1. Integrate a Large Pre-trained Language Model\n",
      "- **Responsible**: Ethan Clark (ML Engineer)\n",
      "- **Estimated Time**: 2 weeks\n",
      "- **Resources**: 1 ML Engineer, cloud resources for model training/integration.\n",
      "- **Effort**: 80 hours\n",
      "- **Risks/Uncertainties**: Selection of the model may fall behind the timeline if validation takes longer than anticipated.\n",
      "\n",
      "#### 2. Implement an Efficient Data Retrieval System\n",
      "- **Responsible**: Maria Green (Data Engineer)\n",
      "- **Estimated Time**: 2 weeks\n",
      "- **Resources**: 1 Data Engineer, infrastructure setup for data storage and retrieval.\n",
      "- **Effort**: 80 hours\n",
      "- **Risks/Uncertainties**: Potential delays in configuration or integration with the language model could extend the timeline.\n",
      "\n",
      "#### 3. Augment Model Generation Process\n",
      "- **Responsible**: Olivia Stone (AI Researcher) & Ethan Clark (ML Engineer)\n",
      "- **Estimated Time**: 2 weeks\n",
      "- **Resources**: 1 AI Researcher, 1 ML Engineer, additional computational resources if higher processing power is needed.\n",
      "- **Effort**: 120 hours (60 hours each)\n",
      "- **Risks/Uncertainties**: The complexity of integrating augmented data may require additional iterations, impacting time and resources.\n",
      "\n",
      "#### 4. Implement Document Ranking and Relevance Scoring\n",
      "- **Responsible**: Sofia Patel (NLP Engineer)\n",
      "- **Estimated Time**: 2 weeks (parallel with augmentation)\n",
      "- **Resources**: 1 NLP Engineer, access to training datasets for algorithm development.\n",
      "- **Effort**: 100 hours\n",
      "- **Risks/Uncertainties**: Algorithms may not perform as expected without sufficient training, leading to more extensive adjustments.\n",
      "\n",
      "#### 5. Process Unstructured Text from Diverse Sources\n",
      "- **Responsible**: Maria Green (Data Engineer)\n",
      "- **Estimated Time**: 4 weeks\n",
      "- **Resources**: 1 Data Engineer, storage and preprocessing frameworks.\n",
      "- **Effort**: 160 hours\n",
      "- **Risks/Uncertainties**: Challenges in handling diverse formats and sources can cause delays in the pipeline setup.\n",
      "\n",
      "#### 6. Fine-tune the LLM on Specific Use-Cases\n",
      "- **Responsible**: Olivia Stone (AI Researcher) & Ethan Clark (ML Engineer)\n",
      "- **Estimated Time**: 2 weeks\n",
      "- **Resources**: 1 ML Engineer, 1 AI Researcher, data for fine-tuning.\n",
      "- **Effort**: 120 hours (60 hours each)\n",
      "- **Risks/Uncertainties**: Fine-tuning may require multiple iterations to achieve the desired output quality.\n",
      "\n",
      "#### 7. Evaluate and Optimize Retrieval Strategy\n",
      "- **Responsible**: Sofia Patel (NLP Engineer) & Ethan Clark (ML Engineer)\n",
      "- **Estimated Time**: 1 week\n",
      "- **Resources**: 1 NLP Engineer, 1 ML Engineer.\n",
      "- **Effort**: 40 hours\n",
      "- **Risks/Uncertainties**: Optimization may reveal unforeseen issues requiring further iterations.\n",
      "\n",
      "#### 8. Test the LLM’s Response Quality\n",
      "- **Responsible**: Liam Allen (QA Engineer)\n",
      "- **Estimated Time**: 1 week\n",
      "- **Resources**: 1 QA Engineer, testing frameworks.\n",
      "- **Effort**: 40 hours\n",
      "- **Risks/Uncertainties**: The scope of tests may increase if initial testing reveals significant output quality issues.\n",
      "\n",
      "#### 9. Implement User Interface\n",
      "- **Responsible**: Ethan Clark (ML Engineer) & Maria Green (Data Engineer)\n",
      "- **Estimated Time**: 1 week\n",
      "- **Resources**: 1 ML Engineer, 1 Data Engineer, frontend development tools.\n",
      "- **Effort**: 40 hours\n",
      "- **Risks/Uncertainties**: User interface requirements may evolve, potentially requiring additional development time.\n",
      "\n",
      "#### 10. Ensure Scalability\n",
      "- **Responsible**: Jack White (Project Manager) & Ethan Clark (ML Engineer)\n",
      "- **Estimated Time**: 1 week\n",
      "- **Resources**: 1 Project Manager, 1 ML Engineer, scalability tools.\n",
      "- **Effort**: 40 hours\n",
      "- **Risks/Uncertainties**: Scalability solutions may require testing iterations, which could affect the schedule.\n",
      "\n",
      "### Summary of Potential Risks and Uncertainties\n",
      "1. **Dependencies**: Many tasks are interconnected; delays in one task can cascade, impacting subsequent tasks.\n",
      "2. **Integration Complexity**: Tasks involving integration (language model, data retrieval, and response generation) pose risks regarding time and effort due to unforeseen technical challenges.\n",
      "3. **Resource Availability**: Changes in personnel or resource availability could affect timelines.\n",
      "4. **Testing Outcomes**: Quality concerns raised during testing may necessitate revisiting earlier stages, impacting the overall timeline.\n",
      "\n",
      "This comprehensive estimation report provides a structured approach to managing the RAG LLM project timeline, resources, and effort required while outlining potential risks that could affect project execution. By proactively addressing these uncertainties, we can minimize disruptions and work towards a successful project delivery.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResource Allocation Strategist\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAssign tasks for the RAG (Retrieval-Augmented Generation) LLM project to the right team members based on their skills, availability, and current workload. Make sure no one is overloaded and that tasks are given to the best-suited person for the job.\n",
      "Team members:\n",
      "\n",
      "- Jack White (Project Manager)\n",
      "- Olivia Stone (AI Researcher)\n",
      "- Ethan Clark (ML Engineer)\n",
      "- Maria Green (Data Engineer)\n",
      "- Sofia Patel (NLP Engineer)\n",
      "- Liam Allen (QA Engineer)\n",
      "\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mResource Allocation Strategist\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "### RAG (Retrieval-Augmented Generation) LLM Project Task Assignment Chart\n",
      "\n",
      "| Task                                           | Team Member(s)                                 | Start Date   | End Date     | Explanation                                               |\n",
      "|------------------------------------------------|------------------------------------------------|--------------|--------------|----------------------------------------------------------|\n",
      "| 1. Integrate a Large Pre-trained Language Model | Ethan Clark (ML Engineer)                      | 2023-10-02   | 2023-10-16   | Ethan is skilled in machine learning and has prior successful integration experiences, making him the best fit for this task. |\n",
      "| 2. Implement an Efficient Data Retrieval System  | Maria Green (Data Engineer)                    | 2023-10-02   | 2023-10-16   | Maria has a strong background in data engineering, ideal for creating efficient data storage and retrieval systems.       |\n",
      "| 3. Augment Model Generation Process              | Olivia Stone (AI Researcher), Ethan Clark (ML Engineer) | 2023-10-16   | 2023-10-30   | Both Olivia's and Ethan's combined skills will ensure effective generation augmentation, leveraging different perspectives in ML and research. |\n",
      "| 4. Implement Document Ranking and Relevance Scoring | Sofia Patel (NLP Engineer)                     | 2023-10-16   | 2023-10-30   | Sofia specializes in NLP tasks, making her well-suited to develop effective ranking and scoring algorithms for documents. |\n",
      "| 5. Process Unstructured Text from Diverse Sources  | Maria Green (Data Engineer)                    | 2023-10-30   | 2023-11-20   | Maria’s expertise in data handling is crucial for processing diverse data formats. Her workload is manageable alongside task 2. |\n",
      "| 6. Fine-tune the LLM on Specific Use-Cases       | Olivia Stone (AI Researcher), Ethan Clark (ML Engineer) | 2023-10-30   | 2023-11-13   | Both team members can draw from their previous work with LLMs, ensuring the model is optimized for specific applications. |\n",
      "| 7. Evaluate and Optimize Retrieval Strategy       | Sofia Patel (NLP Engineer), Ethan Clark (ML Engineer) | 2023-11-13   | 2023-11-20   | Their collaboration ensures comprehensive optimization of retrieval strategies, utilizing their distinct strengths in NLP and ML. |\n",
      "| 8. Test the LLM’s Response Quality                | Liam Allen (QA Engineer)                        | 2023-11-13   | 2023-11-20   | Liam's testing expertise makes him the right choice for evaluating the model’s performance and adherence to quality standards. |\n",
      "| 9. Implement User Interface                        | Ethan Clark (ML Engineer), Maria Green (Data Engineer) | 2023-11-20   | 2023-11-27   | The combined efforts of Ethan and Maria will ensure that the UI is both functional and integrates seamlessly with the backend systems. |\n",
      "| 10. Ensure Scalability                            | Jack White (Project Manager), Ethan Clark (ML Engineer) | 2023-11-27   | 2023-12-04   | Jack's project management skills paired with Ethan's technical knowledge will ensure the project's scalability needs are adequately met. |\n",
      "\n",
      "### Summary of Task Assignments:\n",
      "- **Avoiding Overload**: Each team member's workload is balanced, preventing any one person from being overwhelmed while ensuring efficiency.\n",
      "- **Skills-Based Assignments**: Tasks are assigned to team members based on their strengths and current project demands for optimal outcomes.\n",
      "- **Collaboration Opportunities**: Some tasks involve more than one team member to leverage diverse expertise, enhancing the project's quality and effectiveness.\n",
      "\n",
      "By aligning tasks with individual team member strengths and managing their workloads, the RAG LLM project will progress smoothly towards its goals with a clear structure in place.\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The given Python dictionary\n",
    "inputs = {\n",
    "  'project_type': project,\n",
    "  'project_objectives': project_objectives,\n",
    "  'industry': industry,\n",
    "  'team_members': team_members,\n",
    "  'project_requirements': project_requirements\n",
    "}\n",
    "\n",
    "# Run the crew\n",
    "result = crew.kickoff(\n",
    "  inputs=inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7879258f-52df-4503-b08e-acd516d0a946",
   "metadata": {},
   "source": [
    "## Usage Metrics and Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94dad33-91c9-4aac-8e16-24117dbbef46",
   "metadata": {},
   "source": [
    "Let’s see how much it would cost each time if this crew runs at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66b3b165-2a4b-46cc-93f7-696dffff1e10",
   "metadata": {
    "height": 164
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total costs: $0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\openai-4o\\lib\\site-packages\\pydantic\\main.py:1114: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>successful_requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8525</td>\n",
       "      <td>4772</td>\n",
       "      <td>3753</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_tokens  prompt_tokens  completion_tokens  successful_requests\n",
       "0          8525           4772               3753                    4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "costs = 0.150 * (crew.usage_metrics.prompt_tokens + crew.usage_metrics.completion_tokens) / 1_000_000\n",
    "print(f\"Total costs: ${costs:.4f}\")\n",
    "\n",
    "# Convert UsageMetrics instance to a DataFrame\n",
    "df_usage_metrics = pd.DataFrame([crew.usage_metrics.dict()])\n",
    "df_usage_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982e83a-9e54-4510-9f06-751b34848287",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6396b0f6-e3ae-4a89-a3e9-ca53aa042c40",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\openai-4o\\lib\\site-packages\\pydantic\\main.py:1114: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tasks': [{'task_name': 'Integrate a Large Pre-trained Language Model',\n",
       "   'estimated_time_hours': 14.0,\n",
       "   'required_resources': ['Ethan Clark (ML Engineer)']},\n",
       "  {'task_name': 'Implement an Efficient Data Retrieval System',\n",
       "   'estimated_time_hours': 14.0,\n",
       "   'required_resources': ['Maria Green (Data Engineer)']},\n",
       "  {'task_name': 'Augment Model Generation Process',\n",
       "   'estimated_time_hours': 14.0,\n",
       "   'required_resources': ['Olivia Stone (AI Researcher)',\n",
       "    'Ethan Clark (ML Engineer)']},\n",
       "  {'task_name': 'Implement Document Ranking and Relevance Scoring',\n",
       "   'estimated_time_hours': 14.0,\n",
       "   'required_resources': ['Sofia Patel (NLP Engineer)']},\n",
       "  {'task_name': 'Process Unstructured Text from Diverse Sources',\n",
       "   'estimated_time_hours': 152.0,\n",
       "   'required_resources': ['Maria Green (Data Engineer)']},\n",
       "  {'task_name': 'Fine-tune the LLM on Specific Use-Cases',\n",
       "   'estimated_time_hours': 84.0,\n",
       "   'required_resources': ['Olivia Stone (AI Researcher)',\n",
       "    'Ethan Clark (ML Engineer)']},\n",
       "  {'task_name': 'Evaluate and Optimize Retrieval Strategy',\n",
       "   'estimated_time_hours': 84.0,\n",
       "   'required_resources': ['Sofia Patel (NLP Engineer)',\n",
       "    'Ethan Clark (ML Engineer)']},\n",
       "  {'task_name': 'Test the LLM’s Response Quality',\n",
       "   'estimated_time_hours': 84.0,\n",
       "   'required_resources': ['Liam Allen (QA Engineer)']},\n",
       "  {'task_name': 'Implement User Interface',\n",
       "   'estimated_time_hours': 56.0,\n",
       "   'required_resources': ['Ethan Clark (ML Engineer)',\n",
       "    'Maria Green (Data Engineer)']},\n",
       "  {'task_name': 'Ensure Scalability',\n",
       "   'estimated_time_hours': 56.0,\n",
       "   'required_resources': ['Jack White (Project Manager)',\n",
       "    'Ethan Clark (ML Engineer)']}],\n",
       " 'milestones': [{'milestone_name': 'Model Integration and Data Retrieval Setup',\n",
       "   'tasks': ['1', '2']},\n",
       "  {'milestone_name': 'Model Generation and Document Scoring',\n",
       "   'tasks': ['3', '4']},\n",
       "  {'milestone_name': 'Data Processing and Model Fine-tuning',\n",
       "   'tasks': ['5', '6']},\n",
       "  {'milestone_name': 'Evaluation and User Interface Implementation',\n",
       "   'tasks': ['7', '8', '9']},\n",
       "  {'milestone_name': 'Project Scalability and Conclusion', 'tasks': ['10']}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.pydantic.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ffcc83-350e-4f99-b03b-458690cc0ed2",
   "metadata": {},
   "source": [
    "## Inspect further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da1bbf90-4bfc-4529-84dd-d0bd00198353",
   "metadata": {
    "height": 147
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4a719 th {\n",
       "  font-size: 120%;\n",
       "}\n",
       "#T_4a719  td {\n",
       "  font-size: 120%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4a719\" border=\"1\">\n",
       "  <caption>Task Details</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4a719_level0_col0\" class=\"col_heading level0 col0\" >task_name</th>\n",
       "      <th id=\"T_4a719_level0_col1\" class=\"col_heading level0 col1\" >estimated_time_hours</th>\n",
       "      <th id=\"T_4a719_level0_col2\" class=\"col_heading level0 col2\" >required_resources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4a719_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4a719_row0_col0\" class=\"data row0 col0\" >Integrate a Large Pre-trained Language Model</td>\n",
       "      <td id=\"T_4a719_row0_col1\" class=\"data row0 col1\" >14.000000</td>\n",
       "      <td id=\"T_4a719_row0_col2\" class=\"data row0 col2\" >['Ethan Clark (ML Engineer)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a719_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4a719_row1_col0\" class=\"data row1 col0\" >Implement an Efficient Data Retrieval System</td>\n",
       "      <td id=\"T_4a719_row1_col1\" class=\"data row1 col1\" >14.000000</td>\n",
       "      <td id=\"T_4a719_row1_col2\" class=\"data row1 col2\" >['Maria Green (Data Engineer)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a719_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4a719_row2_col0\" class=\"data row2 col0\" >Augment Model Generation Process</td>\n",
       "      <td id=\"T_4a719_row2_col1\" class=\"data row2 col1\" >14.000000</td>\n",
       "      <td id=\"T_4a719_row2_col2\" class=\"data row2 col2\" >['Olivia Stone (AI Researcher)', 'Ethan Clark (ML Engineer)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a719_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4a719_row3_col0\" class=\"data row3 col0\" >Implement Document Ranking and Relevance Scoring</td>\n",
       "      <td id=\"T_4a719_row3_col1\" class=\"data row3 col1\" >14.000000</td>\n",
       "      <td id=\"T_4a719_row3_col2\" class=\"data row3 col2\" >['Sofia Patel (NLP Engineer)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a719_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_4a719_row4_col0\" class=\"data row4 col0\" >Process Unstructured Text from Diverse Sources</td>\n",
       "      <td id=\"T_4a719_row4_col1\" class=\"data row4 col1\" >152.000000</td>\n",
       "      <td id=\"T_4a719_row4_col2\" class=\"data row4 col2\" >['Maria Green (Data Engineer)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a719_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_4a719_row5_col0\" class=\"data row5 col0\" >Fine-tune the LLM on Specific Use-Cases</td>\n",
       "      <td id=\"T_4a719_row5_col1\" class=\"data row5 col1\" >84.000000</td>\n",
       "      <td id=\"T_4a719_row5_col2\" class=\"data row5 col2\" >['Olivia Stone (AI Researcher)', 'Ethan Clark (ML Engineer)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a719_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_4a719_row6_col0\" class=\"data row6 col0\" >Evaluate and Optimize Retrieval Strategy</td>\n",
       "      <td id=\"T_4a719_row6_col1\" class=\"data row6 col1\" >84.000000</td>\n",
       "      <td id=\"T_4a719_row6_col2\" class=\"data row6 col2\" >['Sofia Patel (NLP Engineer)', 'Ethan Clark (ML Engineer)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a719_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_4a719_row7_col0\" class=\"data row7 col0\" >Test the LLM’s Response Quality</td>\n",
       "      <td id=\"T_4a719_row7_col1\" class=\"data row7 col1\" >84.000000</td>\n",
       "      <td id=\"T_4a719_row7_col2\" class=\"data row7 col2\" >['Liam Allen (QA Engineer)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a719_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_4a719_row8_col0\" class=\"data row8 col0\" >Implement User Interface</td>\n",
       "      <td id=\"T_4a719_row8_col1\" class=\"data row8 col1\" >56.000000</td>\n",
       "      <td id=\"T_4a719_row8_col2\" class=\"data row8 col2\" >['Ethan Clark (ML Engineer)', 'Maria Green (Data Engineer)']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4a719_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_4a719_row9_col0\" class=\"data row9 col0\" >Ensure Scalability</td>\n",
       "      <td id=\"T_4a719_row9_col1\" class=\"data row9 col1\" >56.000000</td>\n",
       "      <td id=\"T_4a719_row9_col2\" class=\"data row9 col2\" >['Jack White (Project Manager)', 'Ethan Clark (ML Engineer)']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e239eeeda0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = result.pydantic.dict()['tasks']\n",
    "df_tasks = pd.DataFrame(tasks)\n",
    "\n",
    "# Display the DataFrame as an HTML table\n",
    "df_tasks.style.set_table_attributes('border=\"1\"').set_caption(\"Task Details\").set_table_styles(\n",
    "    [{'selector': 'th, td', 'props': [('font-size', '120%')]}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210cae8-e028-4f7e-90ed-950ef86d41e5",
   "metadata": {},
   "source": [
    "### Inspecting Milestones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91c2f18c-2d5b-41a9-837b-265e7aa245d0",
   "metadata": {
    "height": 147
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\openai-4o\\lib\\site-packages\\pydantic\\main.py:1114: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2d373 th {\n",
       "  font-size: 120%;\n",
       "}\n",
       "#T_2d373  td {\n",
       "  font-size: 120%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2d373\" border=\"1\">\n",
       "  <caption>Task Details</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2d373_level0_col0\" class=\"col_heading level0 col0\" >milestone_name</th>\n",
       "      <th id=\"T_2d373_level0_col1\" class=\"col_heading level0 col1\" >tasks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2d373_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2d373_row0_col0\" class=\"data row0 col0\" >Model Integration and Data Retrieval Setup</td>\n",
       "      <td id=\"T_2d373_row0_col1\" class=\"data row0 col1\" >['1', '2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d373_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2d373_row1_col0\" class=\"data row1 col0\" >Model Generation and Document Scoring</td>\n",
       "      <td id=\"T_2d373_row1_col1\" class=\"data row1 col1\" >['3', '4']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d373_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_2d373_row2_col0\" class=\"data row2 col0\" >Data Processing and Model Fine-tuning</td>\n",
       "      <td id=\"T_2d373_row2_col1\" class=\"data row2 col1\" >['5', '6']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d373_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_2d373_row3_col0\" class=\"data row3 col0\" >Evaluation and User Interface Implementation</td>\n",
       "      <td id=\"T_2d373_row3_col1\" class=\"data row3 col1\" >['7', '8', '9']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d373_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_2d373_row4_col0\" class=\"data row4 col0\" >Project Scalability and Conclusion</td>\n",
       "      <td id=\"T_2d373_row4_col1\" class=\"data row4 col1\" >['10']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e24387f8e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milestones = result.pydantic.dict()['milestones']\n",
    "df_milestones = pd.DataFrame(milestones)\n",
    "\n",
    "# Display the DataFrame as an HTML table\n",
    "df_milestones.style.set_table_attributes('border=\"1\"').set_caption(\"Task Details\").set_table_styles(\n",
    "    [{'selector': 'th, td', 'props': [('font-size', '120%')]}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a593fd80-36ef-48a1-a7c7-e45c37815f67",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "res = result.raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2c2526-de6d-4006-bd25-8c51e1f3d5f7",
   "metadata": {
    "height": 30
   },
   "source": [
    "### Extact Gann Chart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ac3e1e0-e14f-446e-a912-18794337925c",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Task  \\\n",
      "0                                               Task   \n",
      "1   ------------------------------------------------   \n",
      "2       Integrate a Large Pre-trained Language Model   \n",
      "3       Implement an Efficient Data Retrieval System   \n",
      "4                   Augment Model Generation Process   \n",
      "5   Implement Document Ranking and Relevance Scoring   \n",
      "6     Process Unstructured Text from Diverse Sources   \n",
      "7            Fine-tune the LLM on Specific Use-Cases   \n",
      "8           Evaluate and Optimize Retrieval Strategy   \n",
      "9                    Test the LLM’s Response Quality   \n",
      "10                          Implement User Interface   \n",
      "11                                Ensure Scalability   \n",
      "\n",
      "                                 Assigned Team Member      Start Date  \\\n",
      "0                                      Team Member(s)      Start Date   \n",
      "1    ------------------------------------------------  --------------   \n",
      "2                           Ethan Clark (ML Engineer)      2023-10-02   \n",
      "3                         Maria Green (Data Engineer)      2023-10-02   \n",
      "4   Olivia Stone (AI Researcher), Ethan Clark (ML ...      2023-10-16   \n",
      "5                          Sofia Patel (NLP Engineer)      2023-10-16   \n",
      "6                         Maria Green (Data Engineer)      2023-10-30   \n",
      "7   Olivia Stone (AI Researcher), Ethan Clark (ML ...      2023-10-30   \n",
      "8   Sofia Patel (NLP Engineer), Ethan Clark (ML En...      2023-11-13   \n",
      "9                            Liam Allen (QA Engineer)      2023-11-13   \n",
      "10  Ethan Clark (ML Engineer), Maria Green (Data E...      2023-11-20   \n",
      "11  Jack White (Project Manager), Ethan Clark (ML ...      2023-11-27   \n",
      "\n",
      "          End Date                              Reason for Assignment  \n",
      "0         End Date                                        Explanation  \n",
      "1   --------------  ----------------------------------------------...  \n",
      "2       2023-10-16  Ethan is skilled in machine learning and has p...  \n",
      "3       2023-10-16  Maria has a strong background in data engineer...  \n",
      "4       2023-10-30  Both Olivia's and Ethan's combined skills will...  \n",
      "5       2023-10-30  Sofia specializes in NLP tasks, making her wel...  \n",
      "6       2023-11-20  Maria’s expertise in data handling is crucial ...  \n",
      "7       2023-11-13  Both team members can draw from their previous...  \n",
      "8       2023-11-20  Their collaboration ensures comprehensive opti...  \n",
      "9       2023-11-20  Liam's testing expertise makes him the right c...  \n",
      "10      2023-11-27  The combined efforts of Ethan and Maria will e...  \n",
      "11      2023-12-04  Jack's project management skills paired with E...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Split the response into lines, and extract the relevant part (table content)\n",
    "lines = res.strip().split('\\n')\n",
    "\n",
    "# Skip the first few lines to get to the table data\n",
    "table_lines = lines[2:]  # Skip \"Agent\" and \"Final Answer\" header lines\n",
    "\n",
    "# Clean up each line to extract task details\n",
    "tasks_data = []\n",
    "for line in table_lines:\n",
    "    if line.startswith(\"|\"):  # Only process lines starting with a table\n",
    "        # Remove the initial `|` and split by `|` symbol\n",
    "        columns = [col.strip() for col in line.split('|') if col.strip()]\n",
    "        \n",
    "        if len(columns) == 5:  # Ensure the line is correctly formatted\n",
    "            tasks_data.append({\n",
    "                \"Task\": columns[0],\n",
    "                \"Assigned Team Member\": columns[1],\n",
    "                \"Start Date\": columns[2],\n",
    "                \"End Date\": columns[3],\n",
    "                \"Reason for Assignment\": columns[4]\n",
    "            })\n",
    "\n",
    "# Create a pandas DataFrame from the extracted data\n",
    "df = pd.DataFrame(tasks_data)\n",
    "df[\"Task\"] = df[\"Task\"].apply(lambda x: re.sub(r'^\\d+\\.\\s*', '', x))\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c34b5062-29e2-4fbb-b771-02f5f547e47c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "df = df.drop([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70303180-389e-4e90-8444-aba384ec8751",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "df = df.drop([0]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "109926d3-50e5-43e7-87f8-a1d38e45d79d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Assigned Team Member</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Reason for Assignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Integrate a Large Pre-trained Language Model</td>\n",
       "      <td>Ethan Clark (ML Engineer)</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>Ethan is skilled in machine learning and has p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Implement an Efficient Data Retrieval System</td>\n",
       "      <td>Maria Green (Data Engineer)</td>\n",
       "      <td>2023-10-02</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>Maria has a strong background in data engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Augment Model Generation Process</td>\n",
       "      <td>Olivia Stone (AI Researcher), Ethan Clark (ML ...</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>Both Olivia's and Ethan's combined skills will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Implement Document Ranking and Relevance Scoring</td>\n",
       "      <td>Sofia Patel (NLP Engineer)</td>\n",
       "      <td>2023-10-16</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>Sofia specializes in NLP tasks, making her wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Process Unstructured Text from Diverse Sources</td>\n",
       "      <td>Maria Green (Data Engineer)</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>Maria’s expertise in data handling is crucial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fine-tune the LLM on Specific Use-Cases</td>\n",
       "      <td>Olivia Stone (AI Researcher), Ethan Clark (ML ...</td>\n",
       "      <td>2023-10-30</td>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>Both team members can draw from their previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Evaluate and Optimize Retrieval Strategy</td>\n",
       "      <td>Sofia Patel (NLP Engineer), Ethan Clark (ML En...</td>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>Their collaboration ensures comprehensive opti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Test the LLM’s Response Quality</td>\n",
       "      <td>Liam Allen (QA Engineer)</td>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>Liam's testing expertise makes him the right c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Implement User Interface</td>\n",
       "      <td>Ethan Clark (ML Engineer), Maria Green (Data E...</td>\n",
       "      <td>2023-11-20</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>The combined efforts of Ethan and Maria will e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ensure Scalability</td>\n",
       "      <td>Jack White (Project Manager), Ethan Clark (ML ...</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>2023-12-04</td>\n",
       "      <td>Jack's project management skills paired with E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Task  \\\n",
       "0      Integrate a Large Pre-trained Language Model   \n",
       "1      Implement an Efficient Data Retrieval System   \n",
       "2                  Augment Model Generation Process   \n",
       "3  Implement Document Ranking and Relevance Scoring   \n",
       "4    Process Unstructured Text from Diverse Sources   \n",
       "5           Fine-tune the LLM on Specific Use-Cases   \n",
       "6          Evaluate and Optimize Retrieval Strategy   \n",
       "7                   Test the LLM’s Response Quality   \n",
       "8                          Implement User Interface   \n",
       "9                                Ensure Scalability   \n",
       "\n",
       "                                Assigned Team Member  Start Date    End Date  \\\n",
       "0                          Ethan Clark (ML Engineer)  2023-10-02  2023-10-16   \n",
       "1                        Maria Green (Data Engineer)  2023-10-02  2023-10-16   \n",
       "2  Olivia Stone (AI Researcher), Ethan Clark (ML ...  2023-10-16  2023-10-30   \n",
       "3                         Sofia Patel (NLP Engineer)  2023-10-16  2023-10-30   \n",
       "4                        Maria Green (Data Engineer)  2023-10-30  2023-11-20   \n",
       "5  Olivia Stone (AI Researcher), Ethan Clark (ML ...  2023-10-30  2023-11-13   \n",
       "6  Sofia Patel (NLP Engineer), Ethan Clark (ML En...  2023-11-13  2023-11-20   \n",
       "7                           Liam Allen (QA Engineer)  2023-11-13  2023-11-20   \n",
       "8  Ethan Clark (ML Engineer), Maria Green (Data E...  2023-11-20  2023-11-27   \n",
       "9  Jack White (Project Manager), Ethan Clark (ML ...  2023-11-27  2023-12-04   \n",
       "\n",
       "                               Reason for Assignment  \n",
       "0  Ethan is skilled in machine learning and has p...  \n",
       "1  Maria has a strong background in data engineer...  \n",
       "2  Both Olivia's and Ethan's combined skills will...  \n",
       "3  Sofia specializes in NLP tasks, making her wel...  \n",
       "4  Maria’s expertise in data handling is crucial ...  \n",
       "5  Both team members can draw from their previous...  \n",
       "6  Their collaboration ensures comprehensive opti...  \n",
       "7  Liam's testing expertise makes him the right c...  \n",
       "8  The combined efforts of Ethan and Maria will e...  \n",
       "9  Jack's project management skills paired with E...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-4o",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
